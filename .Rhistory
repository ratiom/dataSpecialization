library(datasets)
?data
data(iris)
?iris
iris
load("C:/Users/Conor/git/Coursera/Data_specialization/UCI HAR Dataset/snapshot20140726.RData")
rm(iris)
gc()
install.packages("KernSmooth")
library(KernSmooth)
load("C:/Users/Conor/git/pubmed/pubmed_macrocycle_query.R.RData")
write.csv(query.unique.name[1001:1201,], filename = new_sample1.csv )
?write.csv
write.csv(query.unique.name[1001:1201,], file = new_sample1.csv )
write.csv(query.unique.name[1001:1201,], "file = new_sample1.csv" )
str(query.unique.name)
write.csv(query.unique.name[4001:4201,], file = "new_sample2.csv" )
write.csv(query.unique.name[6001:6201,], file = "new_sample3.csv" )
library(XML)
fileURL <- ("http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
doc <- xmlTreeParse(fileURL,useInternal=TRUE)
rootNODE <- xmlRoot(doc)
zips <- xpathSApply(rootNODE, "//li[@zipcode='21231']",xmlValue)
doc
fileURL <- ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
doc <- xmlTreeParse(fileURL,useInternal=TRUE)
fileURL <- ("http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
doc <- xmlTreeParse(fileURL,useInternal=TRUE)
library(XML)
doc <- xmlTreeParse(fileURL,useInternal=TRUE)
rootNODE[[1]]
rootNODE[[1]][[1]]
rootNODE[[1]][[1]][[2]]
xmlSApply(rootNODE, xmlValue)
xmlSApply(rootNODE, "//zipcode", xmlValue)
xpathSApply(rootNODE, "//zipcode", xmlValue)
zips <- xpathSApply(rootNODE, "//zipcode='21231'", xmlValue)
zips <- xpathSApply(rootNODE, "//zipcode", xmlValue)
need_zips <- sum("21231", zips)
need_zips <- sum("21231" (zips))
?sum
zips <- xpathSApply(rootNODE, "//zipcode["21231"]", xmlValue)
zips <- xpathSApply(rootNODE, '//zipcode["21231"]', xmlValue)
zips <- xpathSApply(rootNODE, '//zipcode', xmlValue="21231")
zips <- xpathSApply(rootNODE, '//zipcode', xmlValue, "21231")
zips <- xpathSApply(rootNODE, '//zipcode', xmlValue=="21231")
rootNODE[[1]]
zips <- xpathSApply(rootNODE, "//row[zipcode='21231']", xmlValue)
fileURL <- ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv ")
fileURL <- ("http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
doc <- read.csv(fileURL)
getwd()
setwd("C:/Users/Conor/git/dataSpecialization/")
library(data.table)
?fread
DT
DT <- fread(fileURL)
head(DT)
system.time(mean(DT$pwgtp15,by=DT$SEX))
mean(DT$pwgtp15,by=DT$SEX)
?system.time
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(rowMeans(DT)[DT$SEX==1])
system.time(rowMeans(DT)[DT$SEX==2])
race = 1000
meas_tapply <- replicate(race, system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]))
meas_tapply <- replicate(race, system.time(tapply(DT$pwgtp15,DT$SEX,mean))
)
plot(meas_tapply)
race = 100
meas_tapply <- system.time(replicate(race,tapply(DT$pwgtp15,DT$SEX,mean)))
race = 1000
meas_tapply <- system.time(replicate(race,tapply(DT$pwgtp15,DT$SEX,mean)))
meas_tapply <- system.time(replicate(race,DT[,mean(pwgtp15),by=SEX])))
meas_tapply <- system.time(replicate(race,DT[,mean(pwgtp15),by=SEX]))
meas_tapply <- system.time(replicate(race,mean(DT$pwgtp15,by=DT$SEX)))
race = 10000
meas_tapply <- system.time(replicate(race,mean(DT$pwgtp15,by=DT$SEX)))
race = 1000
meas_tapply <- system.time(replicate(race,sapply(split(DT$pwgtp15,DT$SEX),mean)))
meas_tapply <- system.time(replicate(race,mean(DT$pwgtp15,by=DT$SEX)))
